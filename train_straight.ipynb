{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten,\\\n",
    "      MaxPool2D, Conv2D, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0],28,28,1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0],28,28,1).astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "y_train = np_utils.to_categorical(y_train) \n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32, (3,3), input_shape=(28,28,1)))\n",
    "BatchNormalization(axis=-1)\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3)))\n",
    "BatchNormalization(axis=-1)\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "BatchNormalization(axis=-1)\n",
    "\n",
    "classifier.add(Conv2D(64, (3,3)))\n",
    "BatchNormalization(axis=-1)\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "classifier.add(Conv2D(64, (3,3)))\n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "BatchNormalization()\n",
    "\n",
    "classifier.add(Dense(512))\n",
    "BatchNormalization()\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(10))\n",
    "classifier.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rotation_range=10,\n",
    "                               width_shift_range=0.1,\n",
    "                               shear_range=0.3,\n",
    "                               height_shift_range=0.1,\n",
    "                               zoom_range=0.1)\n",
    "test_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = train_gen.flow(x_train,y_train,batch_size=200)\n",
    "test_set = train_gen.flow(x_test,y_test,batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'straight_bs200e80vs60.h5'\n",
    "checkpoint_callback = ModelCheckpoint(model_save_path,\n",
    "                                      monitor='val_accuracy',\n",
    "                                      save_best_only=True,\n",
    "                                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9973 - accuracy: 0.6789\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.89542, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 9s 155ms/step - loss: 0.9973 - accuracy: 0.6789 - val_loss: 0.3379 - val_accuracy: 0.8954\n",
      "Epoch 2/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2718 - accuracy: 0.9140\n",
      "Epoch 00002: val_accuracy improved from 0.89542 to 0.94925, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 10s 159ms/step - loss: 0.2718 - accuracy: 0.9140 - val_loss: 0.1646 - val_accuracy: 0.9492\n",
      "Epoch 3/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1808 - accuracy: 0.9456\n",
      "Epoch 00003: val_accuracy improved from 0.94925 to 0.95575, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 10s 168ms/step - loss: 0.1808 - accuracy: 0.9456 - val_loss: 0.1415 - val_accuracy: 0.9557\n",
      "Epoch 4/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1580 - accuracy: 0.9523\n",
      "Epoch 00004: val_accuracy improved from 0.95575 to 0.96475, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 11s 177ms/step - loss: 0.1580 - accuracy: 0.9523 - val_loss: 0.1049 - val_accuracy: 0.9647\n",
      "Epoch 5/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1256 - accuracy: 0.9603\n",
      "Epoch 00005: val_accuracy improved from 0.96475 to 0.97383, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 11s 176ms/step - loss: 0.1256 - accuracy: 0.9603 - val_loss: 0.0846 - val_accuracy: 0.9738\n",
      "Epoch 6/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.9682\n",
      "Epoch 00006: val_accuracy improved from 0.97383 to 0.97508, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 10s 174ms/step - loss: 0.1083 - accuracy: 0.9682 - val_loss: 0.0777 - val_accuracy: 0.9751\n",
      "Epoch 7/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9697\n",
      "Epoch 00007: val_accuracy improved from 0.97508 to 0.97908, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 10s 171ms/step - loss: 0.1005 - accuracy: 0.9697 - val_loss: 0.0686 - val_accuracy: 0.9791\n",
      "Epoch 8/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.9701\n",
      "Epoch 00008: val_accuracy did not improve from 0.97908\n",
      "60/60 [==============================] - 10s 173ms/step - loss: 0.0911 - accuracy: 0.9701 - val_loss: 0.0647 - val_accuracy: 0.9789\n",
      "Epoch 9/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9737\n",
      "Epoch 00009: val_accuracy improved from 0.97908 to 0.98200, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 10s 173ms/step - loss: 0.0828 - accuracy: 0.9737 - val_loss: 0.0568 - val_accuracy: 0.9820\n",
      "Epoch 10/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9766\n",
      "Epoch 00010: val_accuracy did not improve from 0.98200\n",
      "60/60 [==============================] - 10s 171ms/step - loss: 0.0779 - accuracy: 0.9766 - val_loss: 0.0601 - val_accuracy: 0.9809\n",
      "Epoch 11/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9778\n",
      "Epoch 00011: val_accuracy improved from 0.98200 to 0.98467, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 10s 169ms/step - loss: 0.0692 - accuracy: 0.9778 - val_loss: 0.0506 - val_accuracy: 0.9847\n",
      "Epoch 12/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9757\n",
      "Epoch 00012: val_accuracy did not improve from 0.98467\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.0780 - accuracy: 0.9757 - val_loss: 0.0518 - val_accuracy: 0.9837\n",
      "Epoch 13/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.9812\n",
      "Epoch 00013: val_accuracy improved from 0.98467 to 0.98642, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 10s 167ms/step - loss: 0.0653 - accuracy: 0.9812 - val_loss: 0.0437 - val_accuracy: 0.9864\n",
      "Epoch 14/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9817\n",
      "Epoch 00014: val_accuracy did not improve from 0.98642\n",
      "60/60 [==============================] - 12s 193ms/step - loss: 0.0625 - accuracy: 0.9817 - val_loss: 0.0464 - val_accuracy: 0.9853\n",
      "Epoch 15/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9827\n",
      "Epoch 00015: val_accuracy improved from 0.98642 to 0.98658, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 11s 190ms/step - loss: 0.0557 - accuracy: 0.9827 - val_loss: 0.0431 - val_accuracy: 0.9866\n",
      "Epoch 16/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9843\n",
      "Epoch 00016: val_accuracy improved from 0.98658 to 0.98808, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 10s 171ms/step - loss: 0.0536 - accuracy: 0.9843 - val_loss: 0.0381 - val_accuracy: 0.9881\n",
      "Epoch 17/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9846\n",
      "Epoch 00017: val_accuracy did not improve from 0.98808\n",
      "60/60 [==============================] - 10s 169ms/step - loss: 0.0502 - accuracy: 0.9846 - val_loss: 0.0431 - val_accuracy: 0.9861\n",
      "Epoch 18/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9851\n",
      "Epoch 00018: val_accuracy did not improve from 0.98808\n",
      "60/60 [==============================] - 10s 168ms/step - loss: 0.0472 - accuracy: 0.9851 - val_loss: 0.0468 - val_accuracy: 0.9851\n",
      "Epoch 19/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9839\n",
      "Epoch 00019: val_accuracy did not improve from 0.98808\n",
      "60/60 [==============================] - 12s 198ms/step - loss: 0.0536 - accuracy: 0.9839 - val_loss: 0.0377 - val_accuracy: 0.9880\n",
      "Epoch 20/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9850\n",
      "Epoch 00020: val_accuracy improved from 0.98808 to 0.98817, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 12s 201ms/step - loss: 0.0496 - accuracy: 0.9850 - val_loss: 0.0391 - val_accuracy: 0.9882\n",
      "Epoch 21/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9856\n",
      "Epoch 00021: val_accuracy improved from 0.98817 to 0.98967, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 12s 198ms/step - loss: 0.0482 - accuracy: 0.9856 - val_loss: 0.0286 - val_accuracy: 0.9897\n",
      "Epoch 22/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9852\n",
      "Epoch 00022: val_accuracy did not improve from 0.98967\n",
      "60/60 [==============================] - 10s 168ms/step - loss: 0.0487 - accuracy: 0.9852 - val_loss: 0.0427 - val_accuracy: 0.9869\n",
      "Epoch 23/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9868\n",
      "Epoch 00023: val_accuracy did not improve from 0.98967\n",
      "60/60 [==============================] - 10s 171ms/step - loss: 0.0421 - accuracy: 0.9868 - val_loss: 0.0354 - val_accuracy: 0.9878\n",
      "Epoch 24/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9853\n",
      "Epoch 00024: val_accuracy did not improve from 0.98967\n",
      "60/60 [==============================] - 10s 172ms/step - loss: 0.0480 - accuracy: 0.9853 - val_loss: 0.0324 - val_accuracy: 0.9891\n",
      "Epoch 25/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9866\n",
      "Epoch 00025: val_accuracy improved from 0.98967 to 0.99167, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 10s 168ms/step - loss: 0.0465 - accuracy: 0.9866 - val_loss: 0.0282 - val_accuracy: 0.9917\n",
      "Epoch 26/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9878\n",
      "Epoch 00026: val_accuracy did not improve from 0.99167\n",
      "60/60 [==============================] - 10s 160ms/step - loss: 0.0390 - accuracy: 0.9878 - val_loss: 0.0306 - val_accuracy: 0.9906\n",
      "Epoch 27/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9860\n",
      "Epoch 00027: val_accuracy did not improve from 0.99167\n",
      "60/60 [==============================] - 10s 172ms/step - loss: 0.0437 - accuracy: 0.9860 - val_loss: 0.0348 - val_accuracy: 0.9895\n",
      "Epoch 28/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9881\n",
      "Epoch 00028: val_accuracy did not improve from 0.99167\n",
      "60/60 [==============================] - 10s 173ms/step - loss: 0.0382 - accuracy: 0.9881 - val_loss: 0.0351 - val_accuracy: 0.9889\n",
      "Epoch 29/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9876\n",
      "Epoch 00029: val_accuracy did not improve from 0.99167\n",
      "60/60 [==============================] - 9s 155ms/step - loss: 0.0407 - accuracy: 0.9876 - val_loss: 0.0283 - val_accuracy: 0.9912\n",
      "Epoch 30/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9880\n",
      "Epoch 00030: val_accuracy did not improve from 0.99167\n",
      "60/60 [==============================] - 11s 177ms/step - loss: 0.0397 - accuracy: 0.9880 - val_loss: 0.0283 - val_accuracy: 0.9896\n",
      "Epoch 31/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.9894\n",
      "Epoch 00031: val_accuracy did not improve from 0.99167\n",
      "60/60 [==============================] - 13s 215ms/step - loss: 0.0355 - accuracy: 0.9894 - val_loss: 0.0349 - val_accuracy: 0.9893\n",
      "Epoch 32/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9877\n",
      "Epoch 00032: val_accuracy did not improve from 0.99167\n",
      "60/60 [==============================] - 12s 204ms/step - loss: 0.0413 - accuracy: 0.9877 - val_loss: 0.0340 - val_accuracy: 0.9889\n",
      "Epoch 33/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9890\n",
      "Epoch 00033: val_accuracy did not improve from 0.99167\n",
      "60/60 [==============================] - 10s 170ms/step - loss: 0.0377 - accuracy: 0.9890 - val_loss: 0.0304 - val_accuracy: 0.9894\n",
      "Epoch 34/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9886\n",
      "Epoch 00034: val_accuracy did not improve from 0.99167\n",
      "60/60 [==============================] - 10s 164ms/step - loss: 0.0362 - accuracy: 0.9886 - val_loss: 0.0293 - val_accuracy: 0.9910\n",
      "Epoch 35/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9901\n",
      "Epoch 00035: val_accuracy did not improve from 0.99167\n",
      "60/60 [==============================] - 10s 168ms/step - loss: 0.0331 - accuracy: 0.9901 - val_loss: 0.0298 - val_accuracy: 0.9911\n",
      "Epoch 36/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9895\n",
      "Epoch 00036: val_accuracy improved from 0.99167 to 0.99192, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 10s 171ms/step - loss: 0.0354 - accuracy: 0.9895 - val_loss: 0.0247 - val_accuracy: 0.9919\n",
      "Epoch 37/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9882\n",
      "Epoch 00037: val_accuracy did not improve from 0.99192\n",
      "60/60 [==============================] - 10s 167ms/step - loss: 0.0380 - accuracy: 0.9882 - val_loss: 0.0288 - val_accuracy: 0.9903\n",
      "Epoch 38/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9898\n",
      "Epoch 00038: val_accuracy did not improve from 0.99192\n",
      "60/60 [==============================] - 10s 167ms/step - loss: 0.0315 - accuracy: 0.9898 - val_loss: 0.0309 - val_accuracy: 0.9906\n",
      "Epoch 39/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9888\n",
      "Epoch 00039: val_accuracy did not improve from 0.99192\n",
      "60/60 [==============================] - 10s 167ms/step - loss: 0.0359 - accuracy: 0.9888 - val_loss: 0.0295 - val_accuracy: 0.9913\n",
      "Epoch 40/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9889\n",
      "Epoch 00040: val_accuracy did not improve from 0.99192\n",
      "60/60 [==============================] - 10s 162ms/step - loss: 0.0320 - accuracy: 0.9889 - val_loss: 0.0344 - val_accuracy: 0.9894\n",
      "Epoch 41/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 0.9898\n",
      "Epoch 00041: val_accuracy did not improve from 0.99192\n",
      "60/60 [==============================] - 9s 145ms/step - loss: 0.0297 - accuracy: 0.9898 - val_loss: 0.0275 - val_accuracy: 0.9912\n",
      "Epoch 42/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9906\n",
      "Epoch 00042: val_accuracy did not improve from 0.99192\n",
      "60/60 [==============================] - 9s 145ms/step - loss: 0.0328 - accuracy: 0.9906 - val_loss: 0.0275 - val_accuracy: 0.9909\n",
      "Epoch 43/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9909\n",
      "Epoch 00043: val_accuracy improved from 0.99192 to 0.99267, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 9s 146ms/step - loss: 0.0303 - accuracy: 0.9909 - val_loss: 0.0239 - val_accuracy: 0.9927\n",
      "Epoch 44/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9893\n",
      "Epoch 00044: val_accuracy did not improve from 0.99267\n",
      "60/60 [==============================] - 9s 145ms/step - loss: 0.0369 - accuracy: 0.9893 - val_loss: 0.0263 - val_accuracy: 0.9913\n",
      "Epoch 45/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9902\n",
      "Epoch 00045: val_accuracy did not improve from 0.99267\n",
      "60/60 [==============================] - 10s 161ms/step - loss: 0.0304 - accuracy: 0.9902 - val_loss: 0.0257 - val_accuracy: 0.9923\n",
      "Epoch 46/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9902\n",
      "Epoch 00046: val_accuracy did not improve from 0.99267\n",
      "60/60 [==============================] - 10s 168ms/step - loss: 0.0298 - accuracy: 0.9902 - val_loss: 0.0219 - val_accuracy: 0.9926\n",
      "Epoch 47/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9902\n",
      "Epoch 00047: val_accuracy did not improve from 0.99267\n",
      "60/60 [==============================] - 10s 174ms/step - loss: 0.0272 - accuracy: 0.9902 - val_loss: 0.0244 - val_accuracy: 0.9911\n",
      "Epoch 48/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.9887\n",
      "Epoch 00048: val_accuracy did not improve from 0.99267\n",
      "60/60 [==============================] - 11s 183ms/step - loss: 0.0356 - accuracy: 0.9887 - val_loss: 0.0323 - val_accuracy: 0.9902\n",
      "Epoch 49/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9903\n",
      "Epoch 00049: val_accuracy improved from 0.99267 to 0.99275, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 10s 174ms/step - loss: 0.0326 - accuracy: 0.9903 - val_loss: 0.0246 - val_accuracy: 0.9927\n",
      "Epoch 50/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9923\n",
      "Epoch 00050: val_accuracy did not improve from 0.99275\n",
      "60/60 [==============================] - 10s 173ms/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 0.0266 - val_accuracy: 0.9925\n",
      "Epoch 51/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9910\n",
      "Epoch 00051: val_accuracy did not improve from 0.99275\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.0304 - accuracy: 0.9910 - val_loss: 0.0264 - val_accuracy: 0.9914\n",
      "Epoch 52/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9917\n",
      "Epoch 00052: val_accuracy did not improve from 0.99275\n",
      "60/60 [==============================] - 12s 202ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.0330 - val_accuracy: 0.9894\n",
      "Epoch 53/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 0.9911\n",
      "Epoch 00053: val_accuracy did not improve from 0.99275\n",
      "60/60 [==============================] - 12s 201ms/step - loss: 0.0286 - accuracy: 0.9911 - val_loss: 0.0295 - val_accuracy: 0.9904\n",
      "Epoch 54/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9916\n",
      "Epoch 00054: val_accuracy improved from 0.99275 to 0.99308, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 12s 203ms/step - loss: 0.0251 - accuracy: 0.9916 - val_loss: 0.0219 - val_accuracy: 0.9931\n",
      "Epoch 55/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9916\n",
      "Epoch 00055: val_accuracy did not improve from 0.99308\n",
      "60/60 [==============================] - 12s 200ms/step - loss: 0.0280 - accuracy: 0.9916 - val_loss: 0.0356 - val_accuracy: 0.9893\n",
      "Epoch 56/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9920\n",
      "Epoch 00056: val_accuracy improved from 0.99308 to 0.99350, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 13s 213ms/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 0.0188 - val_accuracy: 0.9935\n",
      "Epoch 57/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9915\n",
      "Epoch 00057: val_accuracy did not improve from 0.99350\n",
      "60/60 [==============================] - 12s 203ms/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 0.0230 - val_accuracy: 0.9927\n",
      "Epoch 58/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9929\n",
      "Epoch 00058: val_accuracy did not improve from 0.99350\n",
      "60/60 [==============================] - 13s 211ms/step - loss: 0.0216 - accuracy: 0.9929 - val_loss: 0.0229 - val_accuracy: 0.9922\n",
      "Epoch 59/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9899\n",
      "Epoch 00059: val_accuracy did not improve from 0.99350\n",
      "60/60 [==============================] - 12s 199ms/step - loss: 0.0320 - accuracy: 0.9899 - val_loss: 0.0263 - val_accuracy: 0.9919\n",
      "Epoch 60/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9919\n",
      "Epoch 00060: val_accuracy did not improve from 0.99350\n",
      "60/60 [==============================] - 12s 200ms/step - loss: 0.0271 - accuracy: 0.9919 - val_loss: 0.0256 - val_accuracy: 0.9922\n",
      "Epoch 61/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9917\n",
      "Epoch 00061: val_accuracy improved from 0.99350 to 0.99425, saving model to straight_bs200e80vs60.h5\n",
      "60/60 [==============================] - 11s 178ms/step - loss: 0.0262 - accuracy: 0.9917 - val_loss: 0.0181 - val_accuracy: 0.9942\n",
      "Epoch 62/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9924\n",
      "Epoch 00062: val_accuracy did not improve from 0.99425\n",
      "60/60 [==============================] - 9s 158ms/step - loss: 0.0247 - accuracy: 0.9924 - val_loss: 0.0248 - val_accuracy: 0.9919\n",
      "Epoch 63/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9919\n",
      "Epoch 00063: val_accuracy did not improve from 0.99425\n",
      "60/60 [==============================] - 10s 169ms/step - loss: 0.0253 - accuracy: 0.9919 - val_loss: 0.0297 - val_accuracy: 0.9909\n",
      "Epoch 64/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9912\n",
      "Epoch 00064: val_accuracy did not improve from 0.99425\n",
      "60/60 [==============================] - 10s 161ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.0282 - val_accuracy: 0.9908\n",
      "Epoch 65/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9924\n",
      "Epoch 00065: val_accuracy did not improve from 0.99425\n",
      "60/60 [==============================] - 9s 147ms/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.0231 - val_accuracy: 0.9923\n",
      "Epoch 66/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9937\n",
      "Epoch 00066: val_accuracy did not improve from 0.99425\n",
      "60/60 [==============================] - 9s 151ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.0212 - val_accuracy: 0.9925\n",
      "Epoch 67/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 0.9919\n",
      "Epoch 00067: val_accuracy did not improve from 0.99425\n",
      "60/60 [==============================] - 11s 178ms/step - loss: 0.0261 - accuracy: 0.9919 - val_loss: 0.0253 - val_accuracy: 0.9916\n",
      "Epoch 68/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9927\n",
      "Epoch 00068: val_accuracy did not improve from 0.99425\n",
      "60/60 [==============================] - 11s 180ms/step - loss: 0.0254 - accuracy: 0.9927 - val_loss: 0.0254 - val_accuracy: 0.9925\n",
      "Epoch 69/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9918\n",
      "Epoch 00069: val_accuracy did not improve from 0.99425\n",
      "60/60 [==============================] - 11s 178ms/step - loss: 0.0266 - accuracy: 0.9918 - val_loss: 0.0255 - val_accuracy: 0.9912\n",
      "Epoch 70/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9918\n",
      "Epoch 00070: val_accuracy did not improve from 0.99425\n",
      "60/60 [==============================] - 11s 181ms/step - loss: 0.0255 - accuracy: 0.9918 - val_loss: 0.0191 - val_accuracy: 0.9939\n",
      "Epoch 71/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9923\n",
      "Epoch 00071: val_accuracy did not improve from 0.99425\n",
      "60/60 [==============================] - 11s 179ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.0254 - val_accuracy: 0.9925\n",
      "Epoch 72/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9923\n",
      "Epoch 00072: val_accuracy did not improve from 0.99425\n",
      "60/60 [==============================] - 9s 158ms/step - loss: 0.0236 - accuracy: 0.9923 - val_loss: 0.0217 - val_accuracy: 0.9929\n",
      "Epoch 73/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9933\n",
      "Epoch 00073: val_accuracy did not improve from 0.99425\n",
      "60/60 [==============================] - 10s 163ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.0234 - val_accuracy: 0.9918\n",
      "Epoch 74/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9932\n",
      "Epoch 00074: val_accuracy did not improve from 0.99425\n",
      "60/60 [==============================] - 13s 217ms/step - loss: 0.0240 - accuracy: 0.9932 - val_loss: 0.0213 - val_accuracy: 0.9937\n",
      "Epoch 75/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9925\n",
      "Epoch 00075: val_accuracy did not improve from 0.99425\n",
      "60/60 [==============================] - 13s 217ms/step - loss: 0.0244 - accuracy: 0.9925 - val_loss: 0.0209 - val_accuracy: 0.9928\n",
      "Epoch 76/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9935\n",
      "Epoch 00076: val_accuracy did not improve from 0.99425\n",
      "60/60 [==============================] - 13s 222ms/step - loss: 0.0193 - accuracy: 0.9935 - val_loss: 0.0246 - val_accuracy: 0.9919\n",
      "Epoch 77/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9936\n",
      "Epoch 00077: val_accuracy did not improve from 0.99425\n",
      "60/60 [==============================] - 13s 215ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 0.0226 - val_accuracy: 0.9918\n",
      "Epoch 78/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.9930\n",
      "Epoch 00078: val_accuracy did not improve from 0.99425\n",
      "60/60 [==============================] - 13s 217ms/step - loss: 0.0224 - accuracy: 0.9930 - val_loss: 0.0216 - val_accuracy: 0.9932\n",
      "Epoch 79/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9931\n",
      "Epoch 00079: val_accuracy did not improve from 0.99425\n",
      "60/60 [==============================] - 13s 219ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.0238 - val_accuracy: 0.9928\n",
      "Epoch 80/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9942\n",
      "Epoch 00080: val_accuracy did not improve from 0.99425\n",
      "60/60 [==============================] - 12s 198ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.0216 - val_accuracy: 0.9937\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit_generator(training_set,\n",
    "                                   steps_per_epoch=60,\n",
    "                                   validation_data=test_set,\n",
    "                                   validation_steps=60,\n",
    "                                   epochs=80,\n",
    "                                   callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'],\n",
    "         label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'],\n",
    "         label='val_accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('correct responses %')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
